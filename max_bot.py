# max_bot_llm_integrated.py

import asyncio
import logging
import time
import importlib.util
import sys
import os
from typing import Dict, Any

import aiomax
from aiomax import fsm
import aiomax.exceptions as am_exc

# ---------- CONFIG ----------
TOKEN = "f9LHodD0cOIXooNwrJaDa_QX6MpAm-djrvXU1imK9BfzBBAKlwDm9Axw7vmFydW0A9Z3Be-dRYTg880Biq-3"  # Ð²ÑÑ‚Ð°Ð²ÑŒ ÑÐ²Ð¾Ð¹ Ñ‚Ð¾ÐºÐµÐ½
SESSION_MINUTES = 40
WEEK_SECONDS = 7 * 24 * 3600  # Ð½ÐµÐ´ÐµÐ»Ñ


# ---------- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ„Ð°Ð¹Ð»Ð° LLM ----------
# ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» LLM Ð² Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¼ÐµÑÑ‚Ð°Ñ… (Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð²Ð°Ð¶ÐµÐ½ â€” Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ).
CANDIDATE_PATHS = [
    # Ñ‚ÐµÐºÑƒÑ‰Ð°Ñ Ð¿Ð°Ð¿ÐºÐ°, Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¸Ð¼ÐµÐ½Ð° Ð²Ð°ÑˆÐ¸Ñ… ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð²
    "chat_lora_session_timer.py",
    "train_lora.py",
    "ÐÐ¾Ð²Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚.txt",
    # ÐµÑÐ»Ð¸ Ð²Ñ‹ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚Ðµ Ð² Windows-Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ñ‚Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¸Ð· Ð»Ð¾Ð³Ð°
    r"C:\Users\EClub\PyCharmMiscProject\chat_lora_session_timer.py",
    r"C:\Users\EClub\PyCharmMiscProject\train_lora.py",
    # Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ñ€Ð°Ð±Ð¾Ñ‡ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ + Ð¸Ð¼Ñ Ð¸Ð· Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° (Ð½Ð° Ñ‚Ð¾Ñ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹, ÐµÑÐ»Ð¸ Ð²Ñ‹ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚Ðµ Ð½Ðµ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°)
    os.path.join(os.getcwd(), "chat_lora_session_timer.py"),
    os.path.join(os.getcwd(), "train_lora.py"),
]

llm_script_path = None
for p in CANDIDATE_PATHS:
    if p and os.path.exists(p):
        llm_script_path = os.path.abspath(p)
        break

if llm_script_path is None:
    # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ â€” Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¾ÑˆÐ¸Ð±ÐºÑƒ Ñ Ð¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð¿ÑƒÑ‚ÐµÐ¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð»Ð¸
    raise FileNotFoundError(
        "Ð¤Ð°Ð¹Ð» ÑÐºÑ€Ð¸Ð¿Ñ‚Ð° Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½. Ð¯ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð» ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð¿ÑƒÑ‚Ð¸:\n"
        + "\n".join(f" - {p}" for p in CANDIDATE_PATHS)
        + "\n\nÐŸÐ¾Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ ÑÐºÑ€Ð¸Ð¿Ñ‚ (Ñ‚Ð¾Ñ‚ Ñ„Ð°Ð¹Ð», ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñƒ Ð²Ð°Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ "
        "'BASE_MODEL_PATH = \"llama_model\"' Ð¸ 'LORA_DIR = \"lora_output\"') Ð² Ð¾Ð´Ð¸Ð½ Ð¸Ð· ÑÑ‚Ð¸Ñ… Ð¿ÑƒÑ‚ÐµÐ¹ "
        "Ð¸Ð»Ð¸ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚Ðµ ÑÐ¿Ð¸ÑÐ¾Ðº CANDIDATE_PATHS Ð² ÐºÐ¾Ð´Ðµ."
    )

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» ÐºÐ°Ðº Ð¼Ð¾Ð´ÑƒÐ»ÑŒ local_llm_module (Ð½Ðµ Ð¼ÐµÐ½ÑÐµÐ¼ ÐµÐ³Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ)
spec = importlib.util.spec_from_file_location("local_llm_module", llm_script_path)
llm_module = importlib.util.module_from_spec(spec)
sys.modules["local_llm_module"] = llm_module
spec.loader.exec_module(llm_module)

# Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ generate_reply Ð¸Ð· Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¼Ð¾Ð´ÑƒÐ»Ñ
generate_reply = llm_module.generate_reply

# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼ Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ
if not hasattr(llm_module, "generate_reply"):
    raise AttributeError(
        f"Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð´ÑƒÐ»ÑŒ {llm_script_path} Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ generate_reply(history). "
        "ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°."
    )

# ---------- BOT ----------
bot = aiomax.Bot(TOKEN, default_format="markdown")

# ---------- HELPERS ----------
def now_ts() -> float:
    return time.time()

async def ai_process(prompt: str) -> str:
    """
    Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÑ‚ generate_reply Ð¸Ð· Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¼Ð¾Ð´ÑƒÐ»Ñ LLM Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ.
    Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ ÐºÐ°Ðº [{'role':'user', 'content': prompt}]; Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ SYSTEM_PROMPT
    Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÑÐ²Ð¾Ð¸ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¸ (llama_model, lora_output).
    """
    try:
        reply = await asyncio.to_thread(llm_module.generate_reply, [{"role": "user", "content": prompt}])
        if not isinstance(reply, str) or not reply.strip():
            return "âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð²ÐµÑ€Ð½ÑƒÐ»Ð° Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¸Ð»Ð¸ Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚."
        return reply.strip()
    except Exception as e:
        logging.exception("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ðµ LLM:")
        return f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}"

def _init_cursor_data() -> Dict[str, Any]:
    return {
        'state': 'COLLECTING',
        'messages': [],
        'ai_busy': False,
        'session_end_ts': None,
        'session_task': None,
        'week_task': None,
        'last_message_after_end': None
    }

async def safe_send(user_id: int, text: str, tries: int = 2, delay_between: float = 0.25):
    for attempt in range(tries):
        try:
            return await bot.send_message(user_id, text)
        except am_exc.InternalError as e:
            logging.warning("InternalError Ð¿Ñ€Ð¸ send_message: %s. ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° %d/%d", e, attempt+1, tries)
            if attempt + 1 < tries:
                await asyncio.sleep(delay_between)
            else:
                logging.exception("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð¾Ðº.")
                raise

# ---------- HANDLERS ----------
@bot.on_bot_start()
async def on_start(pd: aiomax.BotStartPayload, cursor: fsm.FSMCursor):
    data = _init_cursor_data()
    cursor.change_data(data)
    await pd.send(
        "ÐŸÑ€Ð¸Ð²ÐµÑ‚! ðŸ‘‹ Ð Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð¾ ÑÐµÐ±Ðµ Ð¸ ÑÐ²Ð¾Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ñ…. "
        "Ð§ÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ‚Ñ‹ Ñ€Ð°ÑÑÐºÐ°Ð¶ÐµÑˆÑŒ, Ñ‚ÐµÐ¼ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½ÐµÐµ Ð¿Ñ€Ð¾Ð¹Ð´Ñ‘Ñ‚ Ð¿ÐµÑ€Ð²Ð°Ñ ÑÐµÑÑÐ¸Ñ."
    )

@bot.on_command('reweek')
async def cmd_reweek(ctx: aiomax.CommandContext, cursor: fsm.FSMCursor):
    data = cursor.get_data() or _init_cursor_data()
    task = data.get('week_task')
    if task and not task.done():
        task.cancel()
    data = _init_cursor_data()
    cursor.change_data(data)
    await ctx.reply("Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð½ÐµÐ´ÐµÐ»Ð¸ ÑÐ±Ñ€Ð¾ÑˆÐµÐ½. ÐœÐ¾Ð¶ÐµÑˆÑŒ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ ÑÐµÑÑÐ¸ÑŽ, Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ 'Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ'.")

@bot.on_message()
async def on_message(message: aiomax.Message, cursor: fsm.FSMCursor):
    text = (message.content or '').strip()
    if not text:
        await message.reply("ÐŸÑƒÑÑ‚Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ. ÐÐ°Ð¿Ð¸ÑˆÐ¸, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ñ‚ÐµÐºÑÑ‚.")
        return

    data = cursor.get_data() or _init_cursor_data()
    state = data['state']

    # --- Ð¡Ð±Ð¾Ñ€ Ð²Ð²Ð¾Ð´Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ ---
    if state == 'COLLECTING':
        data['messages'].append(text)
        data['state'] = 'READY_TO_START'
        cursor.change_data(data)
        await message.send("Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾, Ñ Ñ‚ÐµÐ±Ñ Ð²Ñ‹ÑÐ»ÑƒÑˆÐ°Ð». ÐšÐ¾Ð³Ð´Ð° Ð±ÑƒÐ´ÐµÑˆÑŒ Ð³Ð¾Ñ‚Ð¾Ð² Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ ÑÐµÑÑÐ¸ÑŽ â€” Ð½Ð°Ð¿Ð¸ÑˆÐ¸ 'Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ'.")
        return

    # --- ÐÐ°Ñ‡Ð°Ð»Ð¾ ÑÐµÑÑÐ¸Ð¸ ---
    if state == 'READY_TO_START':
        if text.lower() in ['Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ', 'start', 'go']:
            data['state'] = 'IN_SESSION'
            data['session_end_ts'] = now_ts() + SESSION_MINUTES * 60
            cursor.change_data(data)

            await message.send("Ð¡ÐµÑÑÐ¸Ñ Ð½Ð°Ñ‡Ð°Ð»Ð°ÑÑŒ")

            # 1ï¸âƒ£ ÐŸÑ€Ð¾Ð³Ñ€ÐµÐ² Ð¼Ð¾Ð´ÐµÐ»Ð¸ â€” ÑÐºÑ€Ñ‹Ñ‚Ñ‹Ð¹, Ð±ÐµÐ· Ð²Ñ‹Ð²Ð¾Ð´Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ
            if not data.get('warmed_up'):
                try:
                    _ = await ai_process(
                        "ÐÐ°Ñ‡Ð½Ð¸ ÑÐµÑÑÐ¸ÑŽ ÐºÐ°Ðº Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚. ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ 'Ð³Ð¾Ñ‚Ð¾Ð²'.",
                    )
                    data['warmed_up'] = True
                    cursor.change_data(data)
                    logging.info("LLM ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ‚Ð° Ð¿ÐµÑ€ÐµÐ´ ÑÐµÑÑÐ¸ÐµÐ¹.")
                except Exception as e:
                    logging.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÐ²Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")

            # 2ï¸âƒ£ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ â€” Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð· Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
            combined = "\n---\n".join(data.get('messages', [])) or "(Ð½ÐµÑ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹)"
            prompt_for_start = (
                f"\n{combined}\n\n"
            )

            data['ai_busy'] = True
            cursor.change_data(data)

            ai_reply = await ai_process(prompt_for_start)
            await message.send(ai_reply)

            data['ai_busy'] = False
            cursor.change_data(data)

            # 3ï¸âƒ£ ÐŸÐ¾ÑÐ»Ðµ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð° â€” Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¾Ð¼ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð½Ðµ Ð²Ð¸Ð´Ð½Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ)
            try:
                _ = await ai_process(
                    "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²ÐµÐ´Ð¸ ÑÐµÐ±Ñ ÐºÐ°Ðº Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ ÑÐµÑÑÐ¸Ð¸: Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð¸ Ð·Ð°Ð´Ð°Ð¹ 1 Ð¼ÑÐ³ÐºÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.",
                )
            except Exception as e:
                logging.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÐµÐ¼ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°: {e}")

            # 4ï¸âƒ£ Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ ÑÐµÑÑÐ¸Ð¸
            async def session_timer(user_id: int, cursor: fsm.FSMCursor):
                await asyncio.sleep(SESSION_MINUTES * 60)
                d = cursor.get_data() or _init_cursor_data()
                d['state'] = 'SESSION_ENDED_WAIT_LAST'
                cursor.change_data(d)
                await safe_send(
                    user_id,
                    "Ð’Ñ€ÐµÐ¼Ñ ÑÐµÑÑÐ¸Ð¸ Ð¿Ð¾Ð´Ð¾ÑˆÐ»Ð¾ Ðº ÐºÐ¾Ð½Ñ†Ñƒ. ÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÑÐ²Ð¾Ñ‘ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, "
                    "Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð» ÑÐ°Ð¼Ð¼ÐµÑ€Ð¸ Ð¸ Ð´Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ."
                )

            data['session_task'] = asyncio.create_task(session_timer(message.user_id, cursor))
            cursor.change_data(data)

        else:
            await message.reply("Ð•ÑÐ»Ð¸ Ð³Ð¾Ñ‚Ð¾Ð² Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ â€” Ð½Ð°Ð¿Ð¸ÑˆÐ¸ 'Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ'.")
        return

    # --- Ð’ Ñ…Ð¾Ð´Ðµ ÑÐµÑÑÐ¸Ð¸ ---
    if state == 'IN_SESSION':
        if data.get('ai_busy'):
            await message.reply("ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸, Ñ ÐµÑ‰Ñ‘ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ.")
            return

        remaining = max(0, int((data.get('session_end_ts') or now_ts()) - now_ts())) // 60
        prompt = f"Ð”Ð¾ ÐºÐ¾Ð½Ñ†Ð° ÑÐµÑÑÐ¸Ð¸ {remaining} Ð¼Ð¸Ð½.\nÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑÐºÐ°Ð·Ð°Ð»: '{text}'"

        data['ai_busy'] = True
        cursor.change_data(data)

        ai_reply = await ai_process(prompt)
        await message.send(ai_reply)

        data['ai_busy'] = False
        cursor.change_data(data)
        return

    # --- Ð¤Ð¸Ð½Ð°Ð» ÑÐµÑÑÐ¸Ð¸ ---
    if state == 'SESSION_ENDED_WAIT_LAST':
        data['last_message_after_end'] = text
        cursor.change_data(data)

        await message.reply("Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾! Ð“Ð¾Ñ‚Ð¾Ð²Ð»ÑŽ ÑÐ°Ð¼Ð¼ÐµÑ€Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸...")

        final_prompt = (
            f'Ð¡ÐµÑÑÐ¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°. ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: "{text}". '
            "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒ ÑÐ°Ð¼Ð¼ÐµÑ€Ð¸ Ð¸ Ð´Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ Ð½Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ."
        )
        summary = await ai_process(final_prompt)
        await message.send(summary)

        await safe_send(message.user_id, "Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ ÑÐµÐ°Ð½Ñ Ð±ÑƒÐ´ÐµÑ‚ Ñ‡ÐµÑ€ÐµÐ· Ð½ÐµÐ´ÐµÐ»ÑŽ.")

        async def week_timer(user_id: int, cursor: fsm.FSMCursor):
            await asyncio.sleep(WEEK_SECONDS)
            await safe_send(
                user_id,
                'ÐÐµÐ´ÐµÐ»Ñ Ð¿Ñ€Ð¾ÑˆÐ»Ð°, Ð¼Ñ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ ÑÐµÑÑÐ¸ÑŽ, ÐºÐ°Ðº Ð±ÑƒÐ´ÐµÑˆÑŒ Ð³Ð¾Ñ‚Ð¾Ð², Ð½Ð°Ð¿Ð¸ÑˆÐ¸ Ð¼Ð½Ðµ "ÐÐ°Ñ‡Ð°Ñ‚ÑŒ".'
            )
            cursor.change_data(_init_cursor_data())

        data['state'] = 'POST_SESSION_WAIT'
        data['week_task'] = asyncio.create_task(week_timer(message.user_id, cursor))
        cursor.change_data(data)
        return

    # --- ÐŸÐ¾ÑÐ»Ðµ Ð½ÐµÐ´ÐµÐ»Ð¸ (Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸) ---
    if state == 'POST_SESSION_WAIT':
        await message.reply("Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ! ÐœÑ‹ ÑÐºÐ¾Ñ€Ð¾ Ð½Ð°Ñ‡Ð½Ñ‘Ð¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ†Ð¸ÐºÐ».")
        return

    # --- fallback ---
    await message.reply("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ. ÐÐ°Ð¿Ð¸ÑˆÐ¸ /start, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð·Ð°Ð½Ð¾Ð²Ð¾.")

# ---------- RUN ----------
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    logging.info("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ LLM-ÑÐºÑ€Ð¸Ð¿Ñ‚: %s", llm_script_path)
    bot.run()
